[[getting-started]]
= Getting Started

[partintro]
--

Loud ML is the first open source deep learning API that makes it simple to prepare, train, and deploy machine learning models and crunch the data stored in your favorite databases without moving the data. The user selects the times series that they want to model and sets the model date ranges, then Loud ML will build the models and save them for inference in production. Loud ML does all the work and removes the complexity of machine learning with Tensorflow.

Here are a few sample use-cases that Loud ML is used for:

* Detecting abnormal dips in user traffic and responding to incidents before they impact customers satisfaction
* Detecting outliers in seasonal fluctuations of e-commerce transactions
* Spotting abnormal load in a distributed database
* Dynamically spotting network traffic patterns and anticipating congestion before it impacts customer experience
* Forecasting capacity, usage, and load imbalance for energy producers and suppliers
* Forecasting demand for inventory and supply chain optimization
* Abnormal fraud pattern detection for mobile network operators
* Predict network equipment failure for maintenance operations planning
* Anticipate disk capacity and discover capacity issues before it hurts
* Knowing the future load in advance and auto scaling virtual instances in the Cloud
* Knowing the future load in advance and saving energy in data centers

[NOTE]
==================================================

Loud ML ships with `unsupervised` learning techniques that do not require labelled data and therefore can produce faster results.
Donut [arXiv 1802.03903](https://arxiv.org/abs/1802.03903) combines the best of unsupervised and supervised learning: users can label abnormal data if they want to, although this label operation remains optional.

==================================================

For the rest of this tutorial, you will be guided through the process of getting Loud ML up and running, taking a peek inside it, and performing basic operations like creating, training, and using your data to get accurate predictions. At the end of this tutorial, you should have a good idea of what Loud ML is, how it works, and hopefully be inspired to see how you can apply ML to your own data and application.
--

== Basic Concepts

There are a few concepts that are core to Loud ML. Understanding these concepts from the outset will tremendously help ease the learning process.

[float]
=== Time Series Database (TSDB)

A time series database (TSDB) is a software system that is optimized for handling time series data —- arrays of numbers indexed by time (a datetime or a datetime range). 

[float]
=== Near Real Time (NRT)

Loud ML is a near real time API that aggregates data from external databases. What this means is there is a slight latency (normally from one to 30 seconds) from the time you index documents in the TSDB until the time it becomes available for search and aggregation performed by Loud ML.

[float]
=== Bucket

A bucket is an external storage system that supports data query and aggregation. For example, it can be a TSDB or any other document source supported by the API. This object is expressed in YAML format and defined in the configuration.

[float]
=== Model

A machine learning model uses features to represent changes in the data. With Loud ML, these features are assigned by the user when creating the model. For example, a feature can be `avg(cpu_load)` to represent the average metric calculed on the document field named `cpu_load`. The features are defined at model creation time and are used both in <<training>> and <<inference>>.

[float]
[[baseline]]
=== Baseline

Data is dynamic and changes over time. A baseline provides a fit for expected normal value, and expected normal range for the data at a given point in time. A good fit is observed when the observed data is contained within a predicted range. For example, if a battery voltage is measured at 9.56V in the current temperature operating conditions and the baseline predicts 9.23V to 9.88V we shall assume normal operating conditions.

[float]
[[training]]
=== Training

Historical data is used to baseline normal patterns in the data. You are training a model to discover the baseline that fits and understands the data. Your training result is saved on the local filesystem, so it does not have to be repeated if not necessary. Training will output the model loss value ie the fitness between the baseline and the original data. A low loss value is a good fit indicator.

[float]
[[inference]]
=== Inference

After training your model, you can perform inference. This means your model can repeat the operations that it knows (or the ones that have been discovered through training) using brand new data. For example, with time series data, running inference means your model will predict future data based on present and past data: if your features are `avg(cpu_temperature)` and `max(cpu_load)`, and your `bucket_interval` is 60s, you will predict the temperature and load in the next minute.

You can run inference using both past history data (usually to verify the model accuracy), and present data.


== Setup Your config.yml File

The first step after installation is to define the buckets that Loud ML can use to find data. You can edit the file `/etc/loudml/config.yml` and add minimal settings such as the address, port, and name of your bucket.

We will define one `numenta` bucket pointing to a database of the same name.

A `bucket` can act as a source to read data or destination to write data depending on the context.

[source,sh]
--------------------------------------------------
cat /etc/loudml/config.yml
---
buckets:
 - name: numenta
   type: influxdb
   addr: localhost
   database: numenta
   measurement: loudml
   create_database: true
   retention_policy: autogen
   max_series_per_request: 2000
 - name: output
   type: influxdb
   addr: localhost
   database: output
   measurement: loudml
   create_database: true
   retention_policy: autogen
   max_series_per_request: 2000
--------------------------------------------------

Or if your `config.yml` settings must specify Elasticsearch indexes:

[source,sh]
--------------------------------------------------
cat /etc/loudml/config.yml
---
buckets:
 - name: numenta
   type: elasticsearch
   addr: localhost
   index: numenta
   doc_type: doc
 - name: output
   type: elasticsearch
   addr: localhost
   index: loudml
   doc_type: doc
--------------------------------------------------

[NOTE]
==================================================

Settings will differ according to the type of database used in your environment. But if your favorite database is missing, we've made it simple to submit a https://raw.githubusercontent.com/regel/loudml/master/CONTRIBUTING.md[pull request] on Github.

==================================================

== Loud ML Python API Client

The `loudml-python` [package](https://pypi.org/project/loudml-python/) available on PyPI is a command line client designed to control the Loud ML model server.

If you’ve installed `loudml-python` locally, the `loudml` command should be available via the command line. Executing loudml will start the CLI and automatically connect to the local Loud ML model server instance (assuming you have already started the server with `systemctl start loudmld` or by running loudmld directly). The output should look like this:

--------------------------------------------------
$ loudml
Connected to localhost:8077 version 1.6.0-577c87de
Loud ML shell 1.6.0-42136d38
>
--------------------------------------------------

Usage:

--------------------------------------------------
$ loudml -h

usage: loudml [-h] [-A ADDR] [-q] [--version] [-e EXECUTE]

    The Python client interface to Loud ML model servers.
    

optional arguments:
  -h, --help            show this help message and exit
  -A ADDR, --addr ADDR  Loud ML model server host and port to connect to.
  -q, --quiet           Quiet: no stdout
  --version             Display the version and exit.
  -e EXECUTE, --execute EXECUTE
                        Execute command and quit.

Examples:

    # Use loudml in a non-interactive mode to output the two days forecast
    # for model "test-model" and pretty print the output:
    $ loudml --execute 'forecast-model -f now -t now+2d test-model'

    # Connect to a specific Loud ML model server:
    $ loudml --addr hostname:8077
--------------------------------------------------


== Historical Data

Public real world data sets are useful for testing. We can load the popular https://github.com/numenta/NAB[NAB] data set using one command. The `-f` flag will offset the data so that it begins at the given point in time. The `-d` flag saves data to the chosen data store defined in your `config.yml` file.

[source,sh]
--------------------------------------------------
loudml -e "load-nab -f now-30d numenta"
--------------------------------------------------

== First Model

Data is loaded. Let's declare a first model in a JSON file. This model learns
the average CPU utilization of an AWS instance auto scaling group. Our JSON
file describes the parameters and features to pull and aggregate data from
a bucket. 

[source,sh]
--------------------------------------------------
cat <<EOF | tee asg.json
{
    "default_bucket": "numenta",
    "name": "cpu_utilization_asg_misconfiguration",
    "type": "donut",
    "features": [
        {
            "metric": "mean",
            "field": "value",
            "name": "mean_value",
            "match_all": [
                {
                    "tag": "file",
                    "value": "cpu_utilization_asg_misconfiguration"
                }
            ],
            "default": null
        }
    ],
    "bucket_interval": "5m",
    "offset": "10s",
    "interval": "60s",
    "max_evals": 21,
    "span": 24
}
EOF
--------------------------------------------------

We can use the CLI to create this model and ten days of historical data for training.

[source,sh]
--------------------------------------------------
loudml -e "create-model asg.json"
loudml -e "train-model -f now-30d -t now-20d cpu_utilization_asg_misconfiguration"
--------------------------------------------------

== Evaluate

We can use the `eval-model` command to compare original data against model predictions,
using historical data. The `-s` flag saves data to the default bucket, and
facilitates data vizualization. The `-a` flag calculates a score to detect anomalies.

Output data points are saved to the `output` bucket and each point contains the following information:

* `@mean_value`: the original data point value or null
* `mean_value`: the predicted normal value named according to the JSON model definition
* `lower_mean_value`: the minimum normal value with 99.7 percent confidence
* `upper_mean_value`: the maximum normal value with 99.7 percent confidence
* `score`: anomaly score in range [0.0, 100.0]
* `is_anomaly`: flag the data point as abnormal or not

[source,sh]
--------------------------------------------------
loudml -e "eval-model cpu_utilization_asg_misconfiguration -f now-30d -t now -s -a -o output"
--------------------------------------------------

Or if you need to print the output to the terminal:

--------------------------------------------------
loudml -e "eval-model cpu_utilization_asg_misconfiguration -f now-30d -t now -a"
--------------------------------------------------

The value between brackets eg `[ 40.9]` is the anomaly score for this data point. This score ranges from 0 to 100. A star `*` indicates that the score is above normal and the data point is therefore flagged as abnormal.

--------------------------------------------------
timestamp          @mean_value         loudml.mean_value  
1567460400.0       35.168             38.212 [ 40.9]     
1567460700.0       46.158             38.709 [ 78.1]     
1567461000.0       39.946             43.764 [ 37.6]     
1567461300.0       33.316             35.549 [ 32.3]     
1567461600.0       57.832             32.826 [* 100.0]   
1567461900.0       31.222             34.417 [ 68.5]     
1567462200.0       33.588             30.978 [ 65.9]     
1567462500.0       30.496             33.961 [ 72.5]     
1567462800.0       39.501             34.369 [ 98.0]     
1567463100.0       46.334             33.238 [* 100.0]   
1567463400.0       31.154             33.193 [ 44.2]     
1567463700.0       31.165             32.515 [ 26.1]     
--------------------------------------------------

== Forecast Future Data

We can use the `forecast` command to generate future data points. Again, the `-s` flag
saves data to the default bucket, and facilitates data vizualization. Response is written to standard output if the `-s` flag is omitted.

[source,sh]
--------------------------------------------------
loudml -e "forecast-model cpu_utilization_asg_misconfiguration -f now-5m -t now+6h"
--------------------------------------------------

Output data points contain the following information:

* `@mean_value`: the original data point value or null
* `mean_value`: the predicted normal value named according to the JSON model definition
* `lower_mean_value`: the minimum normal value with 68 percent confidence.
* `upper_mean_value`: the maximum normal value with 68 percent confidence


The output should look like this:

--------------------------------------------------
timestamp          @mean_value         loudml.mean_value  
1569180000.0       31.829             29.897             
1569180300.0       33.161             32.23              
1569180600.0       31.829             30.063             
1569180900.0       33.203             31.157             
1569181200.0       34.473             33.131
...
--------------------------------------------------

== Detecting Outliers 

Running ML in production requires the ability to automate training, inference, and
forecast operations. Regular scheduled operations, and on demand inference are provided
via the Loud ML model server and the scheduled_job API.

Jobs can be scheduled at a regular `interval`. Using the `start-model` command will schedule a regular job fetching new streaming data and tagging abnormal data points:

[source,sh]
--------------------------------------------------
loudml -e "start-model cpu_utilization_asg_misconfiguration -a"
--------------------------------------------------

Scheduled jobs can be configured to perform other operations too. Refer to the documentation for more advanced usage and examples.

Congratulations on making it this far. We hope this tutorial helps get you started
on your Loud ML journey. Feel free to contribute and submit ideas, bug fixes, and https://raw.githubusercontent.com/regel/loudml/master/CONTRIBUTING.md[pull requests] to enhance the OSS version and the documentation.

Twitter channel: https://twitter.com/loud_ml[@loud_ml]

