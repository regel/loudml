[[timeseries-dsl]]
== Timeseries Features DSL

Defines how time series data must be aggregated into features
for learning and inference.

Features define how to aggregate numerical data from one or more buckets.

Accepted parameters to define model features are:

[horizontal]
`name`:: Name given to this feature
`field`:: TSDB column name
`measurement`:: DEPRECATED. Define `measurement` in the bucket settings.
`match_all`:: list of TSDB tag names and values that must be matched when fetching the data
`metric`:: An aggregation operator supported by the TSDB
`default`:: A default float value to replace NaN values returned by the TSDB, or `previous` in order to fill the series with previous non-NaN value
`anomaly_type`:: `low_high`, `low`, or `high` according to the type of abnormal values to detect

The list below defines the aggregation operators can be used to
define features. These values can be extracted by using numeric
fields in the bucket documents.

[NOTE]
==================================================

This version does not support feature generation by a provided script,
nor extracting features from categories ie, non numeric fields.

==================================================

The `metric` operators that are supported consist of: `count`, `min`, `max`, `sum`,
`avg`, `sum_of_squares`, `variance`, and `std_deviation`.

[NOTE]
==================================================

This version supports the following additional operators with InfluxDB:
`derivative`, `integral`, `spread`, `mode`, `5percentile`, `10percentile`,
`90percentile`, `95percentile`, `stddev`

==================================================

[[dip-user-traffic]]
== A First Example: Abnormal Dips in User Traffic

The easiest time series models have a unique feature. Past values are then
used as a proxy to forecast future values. This unique feature is an `io` ie,
input and output at the same time.

The following `user_traffic.json` file (Or .yml file if YAML format is used)
is using:

* One minute aggregations, ie `bucket_interval` equals 1m
* A window size, ie the span equal to 10 `bucket_interval` ie 10 minutes
* A `low` anomaly type, since we want to detect dips in user traffic

[source,js]
--------------------------------------------------
{
  "bucket_interval": "1m",
  "default_bucket": "my-bucket",
  "features": [
    {
      "default": 0,
      "metric": "count",
      "field": "requests",
      "name": "count_all_requests",
      "anomaly_type": "low"
    }
  ],
  "interval": 60,
  "max_evals": 10,
  "name": "traffic-model",
  "offset": 30,
  "span": 20,
  "max_threshold": 90,
  "min_threshold": 50,
  "type": "donut"
}
--------------------------------------------------

== Advanced Example: Using Filters

Building on the previous example we can use the `match_all` property
to query the data whose `host` value equals `app.xyz.com`

One or more `match_all` conditions can be added to narrow down your search
and will automatically send queries to your buckets with the right filters.

An updated `user_traffic.json` file (Or .yml file if YAML format is used)
will become:

--------------------------------------------------
{
  "name": "traffic-model",
  "bucket_interval": "1m",
  "default_bucket": "my-bucket",
  "features": [
    {
      "match_all": [
        {"tag": "host", "value": "app.xyz.com"}
      ],
      "default": 0,
      "metric": "count",
      "field": "requests",
      "name": "count_all_requests",
      "anomaly_type": "low"
    }
  ],
  "interval": 60,
  "max_evals": 10,
  "offset": 30,
  "span": 20,
  "max_threshold": 90,
  "min_threshold": 50,
  "type": "donut"
}
--------------------------------------------------


